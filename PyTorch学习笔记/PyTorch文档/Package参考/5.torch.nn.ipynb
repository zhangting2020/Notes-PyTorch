{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.nn\n",
    "`作者：Tina`\n",
    "`时间：2018-05-11`\n",
    "\n",
    "本文涉及内容：\n",
    "- Parameters\n",
    "- Containers（容器）\n",
    "- [卷积层](#卷积层)\n",
    "- [池化层](#池化层)\n",
    "- [Padding Layer](#Padding层)\n",
    "- [Non-linear Activations](#非线性激活函数)\n",
    "- [Normalization layer](#归一化层)\n",
    "- Recurrent Layer\n",
    "- [Linear Layer](#线性层)\n",
    "- [Dropout Layer](#Dropout)\n",
    "- [Sparse Layer](#SparseLayer)\n",
    "- [Distance Function](#DistanseFunction)\n",
    "- [Loss Function](#LossFunction)\n",
    "- [Vision Layer](#VisionLayer)\n",
    "- [DataParallel layers](#Multi-GPU)\n",
    "- [Utilities](#Utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "### class torch.nn.Parameter\n",
    "一种模块参数张量。`Parameters`是`Tensor`的子类，`Paramenters`和`Modules`一起使用的时候会有一些特殊的属性，当Paramenters赋值给Module的属性的时候，他会自动的被加到`Module`的参数列表中，并且将出现在`parameters()`迭代器中。当赋值给一个Tensor时就不会有这样的影响，这是因为：有时我们可能想要缓存一些临时状态，如果没有`Parameter`这个类的话，那么这些临时变量也会注册成为模型变量。\n",
    "\n",
    "参数说明：\n",
    "- data：参数张量\n",
    "- requires_grad(bool,optional):默认是True。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 容器(Containers)\n",
    "包含以下内容：\n",
    "- Module\n",
    "- Sequential\n",
    "### class torch.nn.Module\n",
    "所有神经网络模块的基类。你的模型也应该继承这个类。模块还可以包含其他模块，允许将它们嵌套在树形结构中。你可以将子模块赋值给模型属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面方式赋值的`submodule`会被注册。当调用 `.cuda()`的时候，`submodule`的参数也会转换为`cuda Tensor`。\n",
    "#### add_module(name, module)\n",
    "将一个子模块添加到当前模块中。被添加的`module`可以通过`name`属性来获取。\n",
    "参数说明：\n",
    "- name(string)：child module的名字。\n",
    "- module：子模块被添加到这个模块中\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.add_module(\"conv\", nn.Conv2d(10, 20, 4))\n",
    "        #self.conv = nn.Conv2d(10, 20, 4) 和上面这个增加module的方式等价\n",
    "model = Model()\n",
    "print(model.conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply(fn)\n",
    "将fn递归地应用到每一个子模块（由.children()返回）以及self中。典型的使用包括初始化模型的参数。参见`torch.nn.init`。\n",
    "参数说明：\n",
    "- fn：Module->none，应用到每个子模块的函数\n",
    "- 返回：self，类型是module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "net.apply(init_weights) # 将init_weights应用到每一个子模块中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### children()\n",
    "返回当前模型子模块的迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(10, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "Conv2d(20, 10, kernel_size=(4, 4), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.add_module(\"conv\", nn.Conv2d(10, 20, 4))\n",
    "        self.add_module(\"conv1\", nn.Conv2d(20 ,10, 4))\n",
    "model = Model()\n",
    "\n",
    "for sub_module in model.children():\n",
    "    print(sub_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cpu()\n",
    "将所有模型参数和缓冲区复制到CPU。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuda(device=None)\n",
    "将所有的模型参数(parameters)和buffersf复制给GPU。\n",
    "\n",
    "这也把相关的参数和缓冲变成不同的对象。因此，如果模块在优化时使用GPU，在构建优化器之前应该先调用它。\n",
    "#### double()\n",
    "将所有浮点参数和缓冲区都转换为double类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dump_patches = False\n",
    "这使得BC更好地支持`load_state_dict()`。在`state_dict`中，版本号将被保存在返回的`state_dict`的`attribute _metadata`中。因此，`pickled. _metadata`是一个字典，`key`跟随`state_dict`的命名公约。\n",
    "\n",
    "如果新的参数/缓冲区从一个模块中被添加/删除，这个数字将会变化，并且模块的`_load_from_state_dict`方法会比较版本号，并且如果`state dict`来自于之前的改变，还会做适当的修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eval()\n",
    "将模块设置为评估模式。这只对某些模块有影响，当模型中有`Dropout`和`BatchNorm`等就会有影响。\n",
    "#### extra_repr()\n",
    "设置模块的额外表示。\n",
    "\n",
    "打印自定义的额外信息，你应该在你自己的模块中实现这个方法。单行和多行字符串都是可以接受的。\n",
    "#### float()\n",
    "将`parameters`和`buffers`的数据类型转换成`float`。\n",
    "#### forward(*input)\n",
    "定义了每次执行的计算步骤。在所有的子类中都需要重写这个函数。\n",
    "#### half()\n",
    "将`parameters`和`buffers`的数据类型转换成`half`。\n",
    "#### load_state_dict(state_dict, strict=True)\n",
    "将`state_dict`中的`parameters`和`buffers`复制到此模块和它的子后代中。如果`strict`为`True`， 则`state_dict`的`key`必须和模块的`state_dict()`函数返回的`key`一致。用来加载模型参数。\n",
    "\n",
    "参数说明：\n",
    "- state_dict (dict) – 一个包含 parameters 和 persistent buffers（持久化缓存的）字典\n",
    "- strict (bool) – 严格的强制 state_dict 属性中的 key 与该模块的函数的 state_dict() 返回的 keys 相匹配。\n",
    "#### modules()\n",
    "返回一个包含当前模型所有模块的迭代器。重复的模块只返回一次。在下面的例子中，l只返回一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "1 -> Linear(in_features=2, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "l = nn.Linear(2, 2)\n",
    "net = nn.Sequential(l, l)\n",
    "for idx, m in enumerate(net.modules()):\n",
    "    print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### named_children()\n",
    "返回模型当前子模块的迭代器，会产生模块的名称和模块本身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_children():\n",
    "    if name in ['conv4', 'conv5']:\n",
    "        print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### named_modules(memo=None, prefix='')\n",
    "返回网络中所有模块的迭代器，会产生模块的名称和模块本身。重复模块只返回一次。下面的例子中，1将只返回一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('', Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "))\n",
      "1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n"
     ]
    }
   ],
   "source": [
    "l = nn.Linear(2, 2)\n",
    "net = nn.Sequential(l, l)\n",
    "for idx, m in enumerate(net.named_modules()):\n",
    "        print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### named_parameters(memo=None, prefix='')\n",
    "返回模块参数的迭代器, 产生参数的名称以及参数本身。\n",
    "```\n",
    "for name, param in self.named_parameters():\n",
    "    if name in ['bias']:\n",
    "        print(param.size())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters()\n",
    "返回一个模块参数的迭代器。这通常传递给优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([20, 10, 4, 4])\n",
      "<class 'torch.Tensor'> torch.Size([20])\n",
      "<class 'torch.Tensor'> torch.Size([10, 20, 4, 4])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### register_backward_hook(hook)\n",
    "在module上注册一个bachward hook。每次计算module的inputs的梯度的时候，这个hook会被调用。hook应该有以下结构：\n",
    "```python\n",
    "hook(module, grad_input, grad_output) -> Tensor or None\n",
    "```\n",
    "如果module有多个输入输出的话，那么grad_input和grad_output将会是元组。 hook不应该修改它的arguments，但是它可以选择性的返回关于输入的梯度，这个返回的梯度在后续的计算中会替代grad_input。\n",
    "#### register_buffer(name, tensor)\n",
    "向模块添加持久缓冲区。这通常用于注册一个不应该被认为是模型参数的缓冲区，比如`BatchNorm`的`running_maen`不是一个参数，而是持续状态的一部分。\n",
    "缓冲区可以用给定名字访问。\n",
    "参数说明：\n",
    "- name：buffer的名字，是一个string\n",
    "- tensor：被注册的buffer\n",
    "```python\n",
    " self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### register_forward_hook(hook)\n",
    "在module上注册一个forward hook。 每次调用forward()计算输出的时候，这个hook就会被调用。它应该拥有以下结构：\n",
    "```python\n",
    "hook(module, input, output) -> None\n",
    "```\n",
    "hook不应该修改 input和output的值。 这个函数返回一个 句柄(handle)。它有一个方法  handle.remove()，可以用这个方法将hook从module移除\n",
    "#### register_forward_pre_hook(hook)\n",
    "在module上注册一个forward pre-hook。这个hook在`forward()`被调用之前调用。应该有以下结构：\n",
    "```python\n",
    "hook(module, input) -> None\n",
    "```\n",
    "这个hook不应该修改input，返回一个句柄，可以使用`handle.remove`从module中移除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### register_parameter(name, param)\n",
    "向模块添加一个参数。可以使用指定的 name 属性来访问参数。其中`param`是要被添加到模块的参数。\n",
    "#### state_dict(destination=None, prefix='', keep_vars=False)\n",
    "返回一个字典，保存着module的所有状态（state）。包括参数和持久化的缓冲区 (例如运行中的平均值)。`Key`是与之对应的参数和缓冲区的`name`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight', 'bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to(*args, **kwargs)\n",
    "移动和/或转换参数和缓冲区。调用方式：\n",
    "- to(device)\n",
    "- to(dtype)\n",
    "- to(device,dtype)\n",
    "它与`torch.Tensor.to()`有着相似的调用方式，但是不是接受一个Tensor，而是接受一个浮点类型`dtype`。这个方法以原地形式修改了模块。\n",
    "参数说明：\n",
    "- device：参数和缓冲区将要被复制到这个device上\n",
    "- dtype：这个模块中浮点类型参数和缓冲区将要被转换的期望浮点类型\n",
    "返回seft，类型为module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5648, -0.6641],\n",
      "        [-0.0987, -0.6665]])\n",
      "Parameter containing:\n",
      "tensor([[-0.5648, -0.6641],\n",
      "        [-0.0987, -0.6665]], dtype=torch.float64)\n",
      "Parameter containing:\n",
      "tensor([[-0.5649, -0.6641],\n",
      "        [-0.0987, -0.6665]], dtype=torch.float16, device='cuda:1')\n",
      "Parameter containing:\n",
      "tensor([[-0.5649, -0.6641],\n",
      "        [-0.0987, -0.6665]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "linear = nn.Linear(2, 2)\n",
    "print(linear.weight)\n",
    "\n",
    "linear.to(torch.double)\n",
    "print(linear.weight)\n",
    "\n",
    "gpu1 = torch.device(\"cuda:1\")\n",
    "linear.to(gpu1, dtype=torch.half)\n",
    "print(linear.weight)\n",
    "\n",
    "cpu = torch.device(\"cpu\")\n",
    "linear.to(cpu)\n",
    "print(linear.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train(mode=True)\n",
    "把模块设置为训练模式。这只对某些模块有影响，比如`Dropout`和`BatchNorm`\n",
    "#### type(dst_type)\n",
    "将所有参数和缓冲区转换为`dst_type`。\n",
    "#### zero_grad()\n",
    "设置模型参数的梯度为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Sequential(*args)\n",
    "一个顺序容器。模块将按照它们在构造器中传递的顺序添加到其中。或者，也可以传递进来一个模块的有序字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example of using Sequential\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "# Example of using Sequential with OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ModuleList(modules=None)\n",
    "将子模块保存在一个列表中。ModuleList可以像普通的Python列表一样被索引，但是它所包含的模块是正确注册的，并且将被所有的模块方法看到。\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) #在ModuleList中保存了10个nn.Linear(10,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x\n",
    "```\n",
    "#### append(module)\n",
    "将一个给定的模块附加到列表的末尾。\n",
    "#### extend(modules)\n",
    "把Python迭代器中的一个模块添加到列表末尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ParameterList(parameters=None)\n",
    "将参数保存在列表中。参数列表可以像普通的Python列表一样被编入索引，但是它包含的参数被正确地注册，并且所有模块方法都可以看到它。\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ParameterList can act as an iterable, or be indexed using ints\n",
    "        for i, p in enumerate(self.params):\n",
    "            x = self.params[i // 2].mm(x) + p.mm(x)\n",
    "        return x\n",
    "```\n",
    "#### append(parameter)\n",
    "在列表的末尾添加一个给定的参数。\n",
    "#### extend(parameters)\n",
    "在列表最后添加python迭代器中的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <div id=\"卷积层\"></div>卷积层\n",
    "包含内容：\n",
    "- Conv1d\n",
    "- Conv2d\n",
    "- Conv3d\n",
    "- ConvTranspose1d\n",
    "- ConvTranspose2d\n",
    "- ConvTranspose3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "一维卷积层，输入的尺度是$(N, C_in, L)$，输出尺度$(N,C_out,L_out)$：$$ out(N_i, C_{out_j})=bias(C {out_j})+\\sum^{C{in}-1}_{k=0}weight(C{out_j},k) ⋆ input(N_i,k) $$\n",
    "- ⋆是卷积运算符, 上式带 ⋆ 项为卷积项。\n",
    "- N是Batch Size，L是信号序列的长度\n",
    "参数说明：\n",
    "- in_channels(int)：输入信号的通道\n",
    "- out_channels(int)：卷积产生的通道\n",
    "- kerner_size(int or tuple)：卷积核的尺寸\n",
    "- stride: 控制相关系数的计算步长 \n",
    "- dilation: 用于控制卷积核点之间的距离，详细描述在[这里](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) \n",
    "- groups: 控制输入和输出之间的连接，group=1，输出是所有的输入的卷积；group=2，此时相当于有并列的两个卷积层，每个卷积层计算输入通道的一半，并且产生的输出是输出通道的一半，随后将这两个输出连接起来；group=in_channels，每个输入通道与它自己的卷积核集合(size是$\\frac {out_channels} {in_channels}$的向下取整)进行卷积\n",
    "- bias(bool, optional)：如果bias=True，添加偏置\n",
    "\n",
    "注意：数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入整除的时候, 适当的 padding 可以避免这个问题）。\n",
    "**shape**:\n",
    "- 输入: $(N,C_in,L_in)$\n",
    "- 输出: $(N,C_out,L_out)$\n",
    "\n",
    "输入输出的计算方式： \n",
    "$$L_{out}=floor(\\frac {L_{in}+2 \\times padding-dilation(kernerlSize-1)-1} {stride}+1)$$\n",
    "**变量**：\n",
    "- weight(tensor) - 卷积的权重，大小是(out_channels, in_channels, kernel_size) \n",
    "- bias(tensor) - 卷积的偏置系数，大小是（out_channel）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "二维卷积层, 输入的尺度是$(N, C_in,H,W)$，输出尺度$(N,C_{out},H_{out},W_{out})$。\n",
    "\n",
    "**shape**:\n",
    "- input: $(N,C_{in},H_{in},W_{in})$ \n",
    "- output: $(N,C_{out},H_{out},W_{out})$\n",
    "$$H_{out}=floor(\\frac {H_{in}+2 \\times padding[0]-dilation[0](kernerlSize[0]-1)-1)} {stride[0]}+1)$$\n",
    "\n",
    "$$W_{out}=floor(\\frac {W_{in}+2 \\times padding[1]-dilation[1](kernerlSize[1]-1)-1)} {stride[1]}+1)$$\n",
    "\n",
    "**变量**:\n",
    "- weight(tensor) - 卷积的权重，大小是(out_channels, in_channels,kernel_size[0], kernel_size[1])\n",
    "- bias(tensor) - 卷积的偏置系数，大小是（out_channel）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "# non-square kernels and unequal stride and with padding and dilation\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "三维卷积层, 输入的尺度是$(N, C_{in},D,H,W)$，输出尺度$(N,C_out,D_{out},H_{out},W_{out})$的计算方式：\n",
    "**shape**:\n",
    "- input: $(N,C_{in},D_{in},H_{in},W_{in})$ \n",
    "- output: (N,C_{out},D_{out},H_{out},W_{out}) \n",
    "$$D_{out}=floor(\\frac {D_{in}+2 \\times padding[0]-dilation[0](kernerlSize[0]-1)-1} {stride[0]}+1)$$\n",
    "\n",
    "$$H_{out}=floor(\\frac {H_{in}+2 \\times padding[1]-dilation[2](kernerlSize[1]-1)-1} {stride[1]}+1)$$\n",
    "\n",
    "$$W_{out}=floor(\\frac {W_{in}+2 \\times padding[2]-dilation[2](kernerlSize[2]-1)-1} {stride[2]}+1)$$\n",
    "\n",
    "**变量*:\n",
    "weight(tensor) - 卷积的权重，shape是(out_channels, in_channels,kernel_size[0], kernel_size[1], kernel_size[2])\n",
    "bias(tensor) - 卷积的偏置系数，shape是（out_channel）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With square kernels and equal stride\n",
    "m = nn.Conv3d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
    "input = torch.randn(20, 16, 10, 50, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "一维转置卷积操作。这个模块可以被看作是Conv1d关于输入的梯度。有时候也被称为反卷积(deconvolution)，尽管它并不是真正的反卷积操作。\n",
    "因为输入和输出是不是完全的互相关。因此，用户可以进行适当的填充（padding操作）。\n",
    "参数说明：\n",
    "- output_padding：输出的每一条边补充0的数\n",
    "\n",
    "**shape**: \n",
    "- 输入: $(N,C_{in},L_{in})$ \n",
    "- 输出: $(N,C_{out},L_{out})$\n",
    "$$L_{out}=(L_{in}-1)stride-2 \\times padding+kernelSize+outputPadding$$\n",
    "\n",
    "### class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "2维的转置卷积操作。与一维类比。\n",
    "**shape**: \n",
    "- 输入: $(N,C_{in},H_{in}，W_{in})\n",
    "- 输出: $(N,C_{out},H_{out},W_{out})$\n",
    "$$H_{out}=(H_{in}-1) \\times stride[0]-2 \\times padding[0]+kernelSize[0]+outputPadding[0]$$\n",
    "\n",
    "$$W_{out}=(W_{in}-1) \\times stride[1]-2 \\times padding[1]+kernelSize[1]+outputPadding[1]$$\n",
    "\n",
    "变量: \n",
    "- weight(tensor) - 卷积的权重，大小是(in_channels, in_channels,kernel_size[0], kernel_size[1]) \n",
    "- bias(tensor) - 卷积的偏置系数，大小是（out_channel）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 93, 100])\n",
      "torch.Size([1, 16, 6, 6])\n",
      "torch.Size([1, 16, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "# With square kernels and equal stride\n",
    "m = nn.ConvTranspose2d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "\n",
    "# exact output size can be also specified as an argument\n",
    "input = torch.randn(1, 16, 12, 12)\n",
    "downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n",
    "h = downsample(input)\n",
    "print(h.size())\n",
    "output = upsample(h, output_size=input.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "与上面的类比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id=\"池化层\"></div>池化层\n",
    "### class torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "对于输入信号的输入通道，进行1维最大池化（max pooling）操作。如果输入的大小是$(N,C,L)$，那么输出的大小是$(N,C,L_out)$的计算方式是： \n",
    "$$out(N_i, C_j,k)=max_{m=0,...kernel_size-1}input(N_{i},C_j,stride*k+m)$$\n",
    "\n",
    "参数说明：\n",
    "- kernel_size(int or tuple) - max pooling的窗口大小\n",
    "- stride(int or tuple, optional) - max pooling的窗口移动的步长。默认值是kernel_size\n",
    "- padding(int or tuple, optional) - 输入的每一条边补充0的数\n",
    "- dilation(int or tuple, optional) – 一个控制窗口中元素步幅的参数\n",
    "- return_indices - 如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助\n",
    "- ceil_mode - 如果等于True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作\n",
    "\n",
    "**shape**:\n",
    "- 输入: $(N,C_{in},L_{in})$ \n",
    "- 输出: $(N,C_{out},L_{out})$ \n",
    "$$L_{out}=floor(\\frac {L_{in} + 2 \\times padding - dilation(kernel_size - 1) - 1} {stride} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of size=3, stride=2\n",
    "m = nn.MaxPool1d(3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "二维最大池化操作。如果输入的大小是$(N,C,H,W)$，那么输出的大小$(N,C,H_{out},W_{out})$和池化窗口大小$(kH,kW)$的关系是： \n",
    "$$out(N_i, C_j,k)=max_{m=0,...kH-1}max_{m=0,...kW-1}input(N_{i},C_j,stride[0]*h+m,stride[1]*w+n)$$\n",
    "\n",
    "shape: \n",
    "输入: (N,C,H_{in},W_in) \n",
    "输出: (N,C,H_out,W_out) \n",
    "$$H_{out}=floor(\\frac {H_{in} + 2padding[0] - dilation[0](kernel_size[0] - 1) - 1} {stride[0]} + 1$$\n",
    "\n",
    "$$W_{out}=floor(\\frac {W_{in} + 2padding[1] - dilation[1](kernel_size[1] - 1) - 1)} {stride[1]} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "m = nn.MaxPool2d(3, stride=2)\n",
    "# pool of non-square window\n",
    "m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
    "input = torch.randn(20, 16, 50, 32)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "同上面的类似。\n",
    "### class torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0)\n",
    "Maxpool1d的逆过程，不过并不是完全的逆过程，因为在maxpool1d的过程中，一些最大值的已经丢失。 MaxUnpool1d输入MaxPool1d的输出，包括最大值的索引，并计算所有maxpool1d过程中非最大值被设置为零的部分的逆。\n",
    "\n",
    "注意：\n",
    "MaxPool1d可以将多个输入大小映射到相同的输出大小。因此，逆过程可能会变得模棱两可。为了适应这一点，可以在调用中将输出大小（output_size）作为额外的参数传入。 具体用法，请参阅下面的输入和示例。\n",
    "\n",
    "输入：\n",
    "- input:需要转换的input \n",
    "- tensor 索引：由Maxpool1d给出\n",
    "- output_size:一个指定输出大小的torch.Size\n",
    "\n",
    "**shape**:\n",
    "- input: $(N,C,H_{in})$\n",
    "- output:$(N,C,H_{out})$ \n",
    "$$H_{out}=(H_{in}-1)stride[0]-2padding[0]+kernelSize[0]$$ \n",
    "也可以使用output_size指定输出的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.,  4.,  6.,  8.]]])\n",
      "tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0.,  8.]]])\n",
      "tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0.,  8.,  0.]]])\n",
      "tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0.,  8.]]])\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool1d(2, stride=2, return_indices=True)\n",
    "unpool = nn.MaxUnpool1d(2, stride=2)\n",
    "input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]])\n",
    "output, indices = pool(input)\n",
    "print(output)\n",
    "print(unpool(output, indices))\n",
    "\n",
    "# Example showcasing the use of output_size\n",
    "input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
    "output, indices = pool(input)\n",
    "print(unpool(output, indices, output_size=input.size()))\n",
    "\n",
    "print(unpool(output, indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)\n",
    "MaxUnpool2d的输入是MaxPool2d的输出，包括最大值的索引，并计算所有maxpool2d过程中非最大值被设置为零的部分的逆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  0.,   0.,   0.,   0.],\n",
      "          [  0.,   6.,   0.,   8.],\n",
      "          [  0.,   0.,   0.,   0.],\n",
      "          [  0.,  14.,   0.,  16.]]]])\n",
      "tensor([[[[  0.,   0.,   0.,   0.,   0.],\n",
      "          [  6.,   0.,   8.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  14.,   0.],\n",
      "          [ 16.,   0.,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.]]]])\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "unpool = nn.MaxUnpool2d(2, stride=2)\n",
    "input = torch.Tensor([[[[ 1,  2,  3,  4],\n",
    "                        [ 5,  6,  7,  8],\n",
    "                        [ 9, 10, 11, 12],\n",
    "                        [13, 14, 15, 16]]]])\n",
    "output, indices = pool(input)\n",
    "print(unpool(output, indices))\n",
    "# specify a different output size than input siz\n",
    "print(unpool(output, indices, output_size=torch.Size([1, 1, 5, 5])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0)\n",
    "与上面类比。\n",
    "### class torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "一维平均池化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.,  4.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "# pool with window of size=3, stride=2\n",
    "m = nn.AvgPool1d(3, stride=2)\n",
    "print(m(torch.tensor([[[1.,2,3,4,5,6,7]]]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "其中的参数：\n",
    "- count_include_pad：如果等于True，计算平均池化时，将包括padding填充的0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "m = nn.AvgPool2d(3, stride=2)\n",
    "# pool of non-square window\n",
    "m = nn.AvgPool2d((3, 2), stride=(2, 1))\n",
    "input = torch.randn(20, 16, 50, 32)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "同上类似。\n",
    "### class torch.nn.FractionalMaxPool2d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None)\n",
    "二维的[分数最大化池化](https://arxiv.org/abs/1412.6071)。\n",
    "### 更多池化操作\n",
    "参加[全部的池化操作](https://pytorch.org/docs/stable/nn.html#pooling-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id=\"Padding层\"></div> Padding层\n",
    "### class torch.nn.ReflectionPad1d(padding)\n",
    "使用输入边界的反射填充输入张量。\n",
    "- padding (int, tuple) – 填充的大小。如果是int, 则在所有边界填充使用相同的。如果是元组的话，对于一维的就是左右分别填充的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.]]])\n",
      "tensor([[[ 2.,  1.,  0.,  1.,  2.,  3.,  2.,  1.],\n",
      "         [ 6.,  5.,  4.,  5.,  6.,  7.,  6.,  5.]]])\n",
      "tensor([[[ 3.,  2.,  1.,  0.,  1.,  2.,  3.,  2.],\n",
      "         [ 7.,  6.,  5.,  4.,  5.,  6.,  7.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReflectionPad1d(2) #也就是各个边都填充2个数字，数字内容就是input的前两列的倒序\n",
    "input = torch.arange(8).reshape(1, 2, 4)\n",
    "print(input)\n",
    "print(m(input))\n",
    "\n",
    "# using different paddings\n",
    "m = nn.ReflectionPad1d((3, 1)) #左右分别填充3个和1个数\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ReflectionPad2d(padding)\n",
    "参数`padding`，如果是int，所有边界填充大小一样；如果是4元组，则表示上下左右填充的数目（paddingLeft, paddingRight, paddingTop, paddingBottom）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.]]]])\n",
      "tensor([[[[ 8.,  7.,  6.,  7.,  8.,  7.,  6.],\n",
      "          [ 5.,  4.,  3.,  4.,  5.,  4.,  3.],\n",
      "          [ 2.,  1.,  0.,  1.,  2.,  1.,  0.],\n",
      "          [ 5.,  4.,  3.,  4.,  5.,  4.,  3.],\n",
      "          [ 8.,  7.,  6.,  7.,  8.,  7.,  6.],\n",
      "          [ 5.,  4.,  3.,  4.,  5.,  4.,  3.],\n",
      "          [ 2.,  1.,  0.,  1.,  2.,  1.,  0.]]]])\n",
      "tensor([[[[ 7.,  6.,  7.,  8.,  7.],\n",
      "          [ 4.,  3.,  4.,  5.,  4.],\n",
      "          [ 1.,  0.,  1.,  2.,  1.],\n",
      "          [ 4.,  3.,  4.,  5.,  4.],\n",
      "          [ 7.,  6.,  7.,  8.,  7.]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReflectionPad2d(2)\n",
    "input = torch.arange(9).reshape(1, 1, 3, 3) \n",
    "print(input)\n",
    "print(m(input))\n",
    "\n",
    "# using different paddings\n",
    "m = nn.ReflectionPad2d((1, 1, 2, 0))\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ReplicationPad1d(padding)\n",
    "使用输入边界的复制填充输入张量。\n",
    "### class torch.nn.ReplicationPad2d(padding)\n",
    "### class torch.nn.ReplicationPad3d(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.]]]])\n",
      "tensor([[[[ 0.,  0.,  0.,  1.,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  1.,  2.,  2.,  2.],\n",
      "          [ 0.,  0.,  0.,  1.,  2.,  2.,  2.],\n",
      "          [ 3.,  3.,  3.,  4.,  5.,  5.,  5.],\n",
      "          [ 6.,  6.,  6.,  7.,  8.,  8.,  8.],\n",
      "          [ 6.,  6.,  6.,  7.,  8.,  8.,  8.],\n",
      "          [ 6.,  6.,  6.,  7.,  8.,  8.,  8.]]]])\n",
      "tensor([[[[ 0.,  0.,  1.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  2.,  2.],\n",
      "          [ 0.,  0.,  1.,  2.,  2.],\n",
      "          [ 3.,  3.,  4.,  5.,  5.],\n",
      "          [ 6.,  6.,  7.,  8.,  8.]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReplicationPad2d(2)\n",
    "input = torch.arange(9).reshape(1, 1, 3, 3)\n",
    "print(input)\n",
    "print(m(input))\n",
    "\n",
    "# using different paddings\n",
    "m = nn.ReplicationPad2d((1, 1, 2, 0))\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ZeroPad2d(padding)\n",
    "用零填充输入张量边界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2384, -0.3068, -1.1337],\n",
      "          [-0.7758,  0.6120,  0.3402],\n",
      "          [ 0.3969,  1.0994,  0.8858]]]])\n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.2384, -0.3068, -1.1337,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.7758,  0.6120,  0.3402,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.3969,  1.0994,  0.8858,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])\n",
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.2384, -0.3068, -1.1337,  0.0000],\n",
      "          [ 0.0000, -0.7758,  0.6120,  0.3402,  0.0000],\n",
      "          [ 0.0000,  0.3969,  1.0994,  0.8858,  0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.ZeroPad2d(2)\n",
    "input = torch.randn(1, 1, 3, 3)\n",
    "print(input)\n",
    "print(m(input))\n",
    "# using different paddings\n",
    "m = nn.ZeroPad2d((1, 1, 2, 0)) #左，右，上，下填充的数目\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.ConstantPad1d(padding, value)\n",
    "### class torch.nn.ConstantPad2d(padding, value)\n",
    "### class torch.nn.ConstantPad3d(padding, value)\n",
    "用一个常数值填充输入张量边界。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"非线性激活函数\"></div>Non-linear activations (weighted sum, nonlinearity)\n",
    "### class torch.nn.ELU(alpha=1.0, inplace=False)\n",
    "逐元素的应用ELU函数。$ELU(x) = \\max(0,x) + min(0, \\alpha * (exp(x) - 1))$\n",
    "\n",
    "Parameters:\t\n",
    "- alpha – ELU 定义公式中的 alpha 值. 默认值: 1.0\n",
    "- inplace – 选择是否进行覆盖运算 默认值: False\n",
    "### class torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "### class torch.nn.PReLU(num_parameters=1, init=0.25)\n",
    "### class torch.nn.ReLU(inplace=False)\n",
    "### class torch.nn.Sigmoid \n",
    "- Input: (N,∗) * 表示任意维度组合\n",
    "- Output: (N,∗), 与输入有相同的 shape 属性\n",
    "### class torch.nn.Tanh\n",
    "### class torch.nn.Softmax(dim=None)\n",
    "### class torch.nn.Softmax2d\n",
    "对特征图的每一个位置应用softmax\n",
    "Shape:\n",
    "- Input: (N,C,H,W)\n",
    "- Output: (N,C,H,W) (格式 shape 与输入相同)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"归一化层\"></div>Normalization layers\n",
    "- class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "- class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)：小批量 (mini-batch) 数据进行批标准化 (Batch Normalization) 操作。$$y = \\frac {x - E[x]} { \\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta$$ 每个小批量数据中,计算各个维度的均值和标准差。并且$\\gamma$和$\\beta$是大小为 C 的可学习参数向量( C 为输入大小)。在训练过程中，该层持续的计算均值和方差的估计，在预测时使用这些值即可，默认的`momentum`为 0.1。\n",
    "\n",
    "  参数：\n",
    "  - num_features：从输入尺寸中得到C作为num_features。inoput:(N,C,H.W)\n",
    "  - affine：布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数即 gamma 和 beta。\n",
    "  - momentum： 动态均值和动态方差使用的移动动量值,默认为 0.1。\n",
    "\n",
    "  Shape:\n",
    "  - Input: (N,C) or (N,C,L)\n",
    "  - Output: (N,C) or (N,C,L) (same shape as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm2d(100)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layer\n",
    "待补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"线性层\"></div>Linear Layer\n",
    "### class torch.nn.Linear(in_features, out_features, bias=True)\n",
    "对输入数据做线性变换，$y = Ax+b$\n",
    "\n",
    "**参数**\n",
    "- in_features - 每个输入样本的大小\n",
    "- out_features - 每个输出样本的大小\n",
    "- bias - 若设置为False，该层不会学习偏置。默认值：True\n",
    "\n",
    "**Shape**\n",
    "- 输入: $(N,in_features)$\n",
    "- 输出：$(N,out_features)$\n",
    "**变量**\n",
    "- weight -形状为$(OutFeatures * InFeatures)$的模块中可学习的权值\n",
    "- bias -形状为$(OutFeatures)$的模块中可学习的偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True)\n",
    "对输入数据进行双线性变换。$y = x_1 * A * x_2 + b$\n",
    "\n",
    "**参数**\n",
    "- in1_features – 输入一的每个输入样本的大小\n",
    "- in2_features – 输入二的每个输入样本的大小\n",
    "- out_features – 每个输出样本的大小\n",
    "- bias – 若设置为False，这层不会学习偏置。默认值: True\n",
    "\n",
    "**Shape**\n",
    "- Input: $(N,*,In1Features), (N,*,In2Features)$，*表示任意数量的额外维度，除了最后一维，所有的维度应该是相同的\n",
    "- Output: $(N,*,OutFeatures)$除了最后一维，所有的维度与输入相同\n",
    "\n",
    "**变量**\n",
    "- weight – 形状为 $(OutFeatures * In1Features * In2Features)$ 的模块中可学习的权值\n",
    "- bias – 形状为 $(OutFeatures)$ 的模块中可学习的偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Bilinear(20, 30, 40)\n",
    "input1 = torch.randn(128, 20)\n",
    "input2 = torch.randn(128, 30)\n",
    "output = m(input1, input2)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id= \"Dropout\"></div>Dropout layers\n",
    "### class torch.nn.Dropout(p=0.5, inplace=False)\n",
    "在训练期间, 按照伯努利概率分布, 以概率 p 随机地将输入张量中的部分元素设置为0。在每次前向传播调用时, 被置为 0 的元素是随机的。\n",
    "\n",
    "**参数**\n",
    "- p - 将元素置0的概率。默认值：0.5\n",
    "- in-place - 若设置为True，会在原地执行操作。默认值：False\n",
    "\n",
    "**形状**\n",
    "- 输入： 任意。输入可以为任意形状。\n",
    "- 输出： 相同。输出和输入形状相同。\n",
    "\n",
    "在训练中，Dropout的输出通过因子$\\frac 1 {1-p}$进行缩放，保证了在预测时计算的是一个恒等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Dropout(p=0.2)\n",
    "input = torch.randn(20, 16)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Dropout2d(p=0.5, inplace=False)\n",
    "将输入张量的所有通道随机地置为 0。在每次调用时被置为 0 的通道是随机的。通常输入数据来自 Conv2d 模块。\n",
    "\n",
    "论文[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)中提到：如果feature map中的相邻像素是强相关的（在前几层卷积层中很常见），那么独立同分布 的 dropout 将不会正则化激活函数, 相反其会有效地降低学习率。在这样的情况下, 应该使用函数 `nn.Dropout2d` , 它能够提升feature map之间的独立性。\n",
    "\n",
    "**参数**\n",
    "- p(float, optional) - 将元素置0的概率。\n",
    "- inplace(bool, optional) - 若设置为True，会在原地执行操作。\n",
    "\n",
    "**形状**\n",
    "- 输入： (N,C,H,W)\n",
    "- 输出： (N,C,H,W)（与输入形状相同）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.5373, -0.3664, -0.4707,  ...,  1.1798, -0.9644, -1.0320],\n",
      "          [ 1.0244, -0.8318,  2.6734,  ...,  1.0601,  1.5372,  2.0316],\n",
      "          [ 1.5146,  0.8250,  0.1793,  ...,  0.6082, -0.9119,  0.3943],\n",
      "          ...,\n",
      "          [ 0.0216, -1.5690,  1.2650,  ...,  2.2220,  0.5010,  2.8211],\n",
      "          [-1.7106,  0.1823, -0.7618,  ...,  0.0459, -0.9736, -0.3225],\n",
      "          [-0.0267,  0.1126, -0.9643,  ...,  1.1822, -0.0366, -0.1795]],\n",
      "\n",
      "         [[ 1.0853, -1.6172,  0.1729,  ...,  0.5486, -0.4387,  0.6518],\n",
      "          [-1.3613,  0.4653,  2.1923,  ..., -0.3632, -0.9289,  1.5911],\n",
      "          [ 1.7251,  0.2236,  0.2423,  ...,  1.6110,  1.0571,  0.0913],\n",
      "          ...,\n",
      "          [ 0.6831,  2.1183,  0.6529,  ..., -1.8377, -1.9571,  2.9264],\n",
      "          [-0.6733,  0.3157, -0.9592,  ..., -0.8292,  1.1525, -2.6826],\n",
      "          [-2.0278,  2.3075, -1.1850,  ..., -1.5066,  1.3144, -1.6762]],\n",
      "\n",
      "         [[ 2.1537,  1.0038, -1.2062,  ..., -1.4361, -0.5517,  1.1747],\n",
      "          [-0.2129, -1.1561, -0.5705,  ..., -1.6060,  0.3831, -0.7021],\n",
      "          [ 1.7872,  0.6413,  0.2363,  ...,  0.3135, -0.3476, -0.8584],\n",
      "          ...,\n",
      "          [-0.4078,  0.4650, -0.2932,  ..., -0.2254, -0.5480,  1.1916],\n",
      "          [ 0.3720, -0.1286, -0.0463,  ...,  0.5288,  0.9627, -0.8331],\n",
      "          [ 2.8526,  1.0628, -0.1871,  ..., -1.5933, -0.2718,  0.2871]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9327,  0.5419, -0.3116,  ..., -0.0461, -0.9037, -0.3358],\n",
      "          [-0.6828, -0.9000,  0.7132,  ...,  0.7021, -1.6794,  0.4146],\n",
      "          [ 1.2881,  0.2331, -1.4968,  ...,  1.8941,  1.3794,  2.1201],\n",
      "          ...,\n",
      "          [-0.2789, -0.9654, -1.6181,  ..., -1.2672, -1.0564, -1.3870],\n",
      "          [-1.3105,  0.1387, -1.4807,  ...,  0.8915, -0.4166,  1.8737],\n",
      "          [-0.3074, -1.1514, -0.2511,  ..., -0.7532,  1.8900, -0.6387]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.2898,  1.1674, -1.1721,  ..., -1.2946,  1.3098, -0.8371],\n",
      "          [-0.5395, -1.3563,  0.5621,  ...,  0.0240, -0.3104, -0.4881],\n",
      "          [-2.0511, -1.6226,  1.9004,  ..., -0.0101,  0.2590,  2.9983],\n",
      "          ...,\n",
      "          [ 1.5467,  1.3229,  0.2837,  ...,  1.5037, -0.0588,  0.5042],\n",
      "          [-1.5021, -0.1827,  1.6247,  ..., -2.5203, -1.7722,  2.0124],\n",
      "          [ 0.7867,  2.2163, -0.1964,  ...,  2.4628,  0.7795,  1.3431]]],\n",
      "\n",
      "\n",
      "        [[[-0.0097,  2.2599, -1.5989,  ..., -1.9373,  0.9415,  0.4641],\n",
      "          [ 2.7574, -0.8521,  0.5811,  ...,  1.0145,  1.3811, -0.5210],\n",
      "          [-0.1944,  0.6782,  0.2243,  ...,  1.5413, -0.6857, -0.3642],\n",
      "          ...,\n",
      "          [-1.7302, -0.1187,  0.2462,  ..., -0.7119, -1.0158,  1.2840],\n",
      "          [ 1.8444,  1.7041,  0.9248,  ..., -0.7184, -0.5570, -0.1740],\n",
      "          [ 0.5508, -0.6038,  0.0774,  ...,  1.3666, -2.3353, -0.7864]],\n",
      "\n",
      "         [[-0.7948, -1.5849,  0.8472,  ..., -0.8315,  1.8982,  2.3245],\n",
      "          [-0.7632, -1.0020,  1.0208,  ...,  1.7975, -0.4814, -0.6414],\n",
      "          [-2.1652, -0.6565,  2.3942,  ..., -3.0037,  0.2120, -0.1532],\n",
      "          ...,\n",
      "          [ 1.6101, -1.9853,  0.7091,  ..., -0.2235,  2.0552,  0.8522],\n",
      "          [-0.4449, -0.2290, -0.7950,  ...,  0.7164, -0.9996,  1.2050],\n",
      "          [-1.0340, -0.0393, -0.3660,  ...,  0.0503,  1.3076, -0.2607]],\n",
      "\n",
      "         [[-0.1887,  2.0669, -0.4586,  ...,  0.4235, -1.1247, -0.4679],\n",
      "          [-0.1685, -0.0339,  1.1305,  ...,  1.4267, -1.2855,  0.9313],\n",
      "          [ 0.9649, -0.5505,  0.6263,  ..., -0.9096,  0.2579, -0.8901],\n",
      "          ...,\n",
      "          [-0.7386,  0.3478, -1.6258,  ...,  0.0831, -0.8244,  0.3343],\n",
      "          [-0.8872,  0.1646, -1.2402,  ..., -0.9252,  0.6536, -1.5580],\n",
      "          [-0.9963, -1.4899,  0.2093,  ..., -0.8926, -1.0156,  0.2657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2428, -1.1840, -1.7017,  ...,  0.9620,  1.1505,  0.1899],\n",
      "          [-1.2392,  0.6730, -1.2846,  ..., -0.9673, -0.2557,  0.6276],\n",
      "          [ 0.3755,  0.4976,  1.8169,  ..., -0.2090, -0.8636,  0.3879],\n",
      "          ...,\n",
      "          [ 0.2758, -0.9913, -1.8912,  ..., -0.1402,  1.9600,  0.7621],\n",
      "          [ 0.5172, -0.6465, -1.1401,  ...,  0.6137,  0.8762, -2.4073],\n",
      "          [-2.5273,  0.8971,  0.0060,  ...,  2.0394, -0.3168,  0.4704]],\n",
      "\n",
      "         [[-0.3747, -1.9280,  1.7874,  ...,  0.0552,  0.9242,  0.5397],\n",
      "          [ 1.3126,  0.3124,  2.2972,  ...,  0.7919, -0.6505, -1.3794],\n",
      "          [-1.6571,  1.0654,  0.5596,  ..., -0.2743, -0.8469, -0.6306],\n",
      "          ...,\n",
      "          [-0.3905, -0.5988,  1.1599,  ...,  0.6101,  1.9409,  0.0763],\n",
      "          [-1.6430, -0.2578, -0.1056,  ..., -1.4680,  0.9458, -0.4639],\n",
      "          [-0.1242,  0.8159, -0.8632,  ..., -0.9490,  0.6794, -1.3995]],\n",
      "\n",
      "         [[-0.1957,  1.4449,  1.1281,  ...,  0.0480,  0.4374, -0.2721],\n",
      "          [-0.2084,  0.4984,  0.6039,  ...,  0.7486, -0.9792, -2.9216],\n",
      "          [-3.6211,  0.0897, -1.3675,  ...,  1.6229, -0.8275, -2.1789],\n",
      "          ...,\n",
      "          [-0.5369, -0.4699, -0.0326,  ...,  1.6685,  1.6233, -2.0878],\n",
      "          [-1.5596,  1.4951, -2.1020,  ..., -2.1323, -1.2363,  1.3946],\n",
      "          [-0.2698,  1.4997, -0.3213,  ..., -0.0604, -2.1424,  0.3691]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.1241, -0.1091,  0.4775,  ..., -1.2459, -0.7519,  1.7502],\n",
      "          [ 1.1819,  0.9616, -0.7190,  ...,  1.9687,  0.3654,  0.9157],\n",
      "          [ 0.0245,  0.2819,  2.7820,  ...,  0.7229,  0.3304,  0.4041],\n",
      "          ...,\n",
      "          [-0.7105, -1.7555, -2.4496,  ...,  1.1919, -0.5963, -0.3285],\n",
      "          [-1.1036,  0.5951,  2.3539,  ..., -1.2756, -1.7242, -0.6918],\n",
      "          [ 2.3566, -0.3385,  0.7757,  ...,  1.0966,  0.2061, -0.4441]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7789, -1.3309,  1.7595,  ...,  0.0629, -0.4098,  0.5091],\n",
      "          [ 1.5977,  0.8473,  0.3122,  ..., -0.0015, -0.6887, -3.0238],\n",
      "          [ 0.4330,  0.6048, -0.2737,  ..., -1.4254, -0.1221, -4.4753],\n",
      "          ...,\n",
      "          [-0.5807, -1.8346, -0.0351,  ..., -0.9114,  1.7594, -0.6792],\n",
      "          [-0.3342,  1.6722, -0.0124,  ..., -0.2804,  0.5385,  0.1344],\n",
      "          [-0.2304,  0.5740,  0.8917,  ...,  0.2894, -0.3746,  0.9906]],\n",
      "\n",
      "         [[-0.9790, -1.2124,  0.6267,  ..., -0.0818,  0.3181,  0.1039],\n",
      "          [-0.4643, -1.7356,  0.6547,  ...,  0.1969,  1.3064, -0.2092],\n",
      "          [-2.0429, -1.7886, -0.2408,  ..., -0.4698, -0.7830, -2.4106],\n",
      "          ...,\n",
      "          [-0.5936,  1.2797,  0.3876,  ...,  0.2020,  0.2229,  1.8056],\n",
      "          [-1.4502,  1.3560, -1.5936,  ...,  2.3849,  0.7179, -0.9873],\n",
      "          [ 0.7501, -0.0128,  0.0950,  ..., -1.4157,  0.3418,  0.6045]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4523,  0.6343,  1.6353,  ...,  0.4062, -0.4867, -1.6108],\n",
      "          [ 0.3069, -0.9579,  0.7982,  ...,  1.4524,  0.6237,  1.1895],\n",
      "          [-1.1024,  0.8649,  1.3134,  ..., -0.0661, -1.7111,  1.0358],\n",
      "          ...,\n",
      "          [-0.6174,  1.1403, -0.2519,  ...,  1.6909,  2.0881, -2.1063],\n",
      "          [ 2.8151, -1.9051, -4.1557,  ...,  0.9541,  1.8583, -0.8415],\n",
      "          [ 0.8181,  1.0621,  0.7816,  ..., -0.9688,  1.4289,  0.2810]],\n",
      "\n",
      "         [[-1.3731,  0.5140,  0.8531,  ..., -2.5609,  0.8839, -2.3785],\n",
      "          [-0.3109,  1.6139,  0.8183,  ..., -1.5419, -2.1616, -2.5039],\n",
      "          [-0.5630,  1.1063,  0.7088,  ...,  1.0190,  0.1016,  0.4362],\n",
      "          ...,\n",
      "          [ 1.4127, -0.1193,  0.8951,  ...,  0.6928,  0.0452,  2.0474],\n",
      "          [-0.8714,  0.5882,  0.3489,  ..., -2.0931, -1.1722, -0.3183],\n",
      "          [ 1.8103, -2.3829,  0.7224,  ..., -1.0825, -1.8185, -1.3281]],\n",
      "\n",
      "         [[-0.1180,  3.5097, -1.8149,  ...,  1.3154, -2.5492,  0.5066],\n",
      "          [-1.4667, -1.4589, -0.9497,  ...,  2.1325, -0.5986, -1.4643],\n",
      "          [ 0.6763, -1.5507, -1.8641,  ...,  0.7481,  0.0979,  2.8221],\n",
      "          ...,\n",
      "          [-1.5482, -0.9721, -1.2385,  ...,  1.8982,  1.9891,  0.3871],\n",
      "          [-0.7242,  1.5902, -0.6312,  ..., -2.1092, -2.6398,  1.0627],\n",
      "          [-0.5470, -1.6509, -0.6869,  ..., -0.8886,  1.0639, -1.4859]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.8824, -0.1052,  1.1643,  ...,  2.6807, -0.2640,  0.6677],\n",
      "          [-0.4753, -0.6639,  0.0329,  ..., -0.2311,  0.3750,  0.1880],\n",
      "          [-1.6553, -0.8119,  2.7460,  ..., -0.9127,  1.8692,  2.7222],\n",
      "          ...,\n",
      "          [ 0.8557,  1.1492,  1.1862,  ..., -0.0320, -1.9560,  0.4523],\n",
      "          [ 0.9019, -1.3802,  2.0816,  ..., -2.4161, -0.1997, -1.4790],\n",
      "          [ 0.7810, -0.3606,  2.1029,  ..., -0.1909, -3.1046, -0.0332]],\n",
      "\n",
      "         [[ 1.7784, -1.9393,  0.7294,  ..., -0.3727, -0.7708, -0.0907],\n",
      "          [ 0.3341,  1.0405,  0.5773,  ..., -0.0845, -0.1549, -0.3325],\n",
      "          [-0.4938,  1.0267,  1.3465,  ..., -1.5564,  0.2056,  2.4466],\n",
      "          ...,\n",
      "          [-0.6029,  0.9357, -0.9173,  ...,  1.2840, -2.7125,  0.0601],\n",
      "          [ 2.5142,  0.3391, -1.0029,  ..., -1.3689, -0.4785,  0.6021],\n",
      "          [ 1.2970, -1.8894, -0.8584,  ..., -1.2339,  0.4942,  0.7273]]],\n",
      "\n",
      "\n",
      "        [[[-1.9185, -0.7063, -0.3093,  ...,  0.3830,  1.4652, -1.8163],\n",
      "          [-0.0377,  0.1293, -1.0158,  ..., -1.0672, -0.5978,  0.4465],\n",
      "          [-0.6524,  1.4338,  0.1847,  ...,  0.7219,  0.6484, -1.0581],\n",
      "          ...,\n",
      "          [ 0.6948,  0.5883, -0.1275,  ...,  0.8906,  1.5028,  0.4091],\n",
      "          [ 2.4140,  1.0030,  1.5977,  ...,  0.0099, -0.4512, -2.2978],\n",
      "          [ 0.3043,  0.8865,  0.4439,  ...,  0.1688,  1.7204, -0.7499]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6667, -0.6839, -1.1322,  ..., -1.6409, -2.1539,  3.3541],\n",
      "          [ 1.4240,  2.4349, -0.9840,  ..., -0.2125,  0.6604,  0.4425],\n",
      "          [ 1.2945, -1.4434,  0.3006,  ..., -0.4393,  1.4977,  0.9799],\n",
      "          ...,\n",
      "          [ 0.1777,  1.2623, -1.8445,  ..., -0.1042,  2.6180,  1.6636],\n",
      "          [ 1.6087, -0.1362,  1.2255,  ..., -1.1133,  1.4556, -0.1083],\n",
      "          [ 2.3351, -3.0866,  0.1564,  ..., -0.1603,  0.5085, -0.8994]],\n",
      "\n",
      "         [[ 2.5878, -0.7938,  1.6027,  ...,  0.7590, -1.1982, -1.6186],\n",
      "          [ 0.6288,  1.1419,  1.1576,  ..., -1.0812,  0.5740, -3.0160],\n",
      "          [ 0.4411,  0.4024, -0.0306,  ...,  0.3990, -1.6296,  0.2460],\n",
      "          ...,\n",
      "          [-1.6522, -0.6331,  0.2856,  ...,  1.1599, -2.0138,  0.1544],\n",
      "          [-0.2047,  0.5842,  1.1565,  ..., -0.5554,  0.8124,  1.4503],\n",
      "          [-0.7951, -0.6955, -0.4652,  ...,  1.5788, -2.6984,  0.2290]],\n",
      "\n",
      "         [[ 0.0853,  1.7159, -0.3920,  ...,  1.0351, -1.1417,  0.4836],\n",
      "          [ 0.2928,  1.4101,  0.5654,  ...,  3.3600, -1.4158,  0.5214],\n",
      "          [-0.5722, -0.2898, -0.7060,  ...,  0.6695, -1.5960, -0.2301],\n",
      "          ...,\n",
      "          [-1.2355,  1.0952,  0.2001,  ...,  1.8311, -0.0624,  0.1630],\n",
      "          [-2.5044,  1.1815, -2.4955,  ...,  0.4811,  0.2332, -1.5202],\n",
      "          [-1.2192, -3.4314, -0.4951,  ...,  1.6456, -0.7140, -1.3736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          ...,\n",
      "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-2.1369, -0.2246,  0.8216,  ...,  0.5867,  1.0800, -0.4271],\n",
      "          [ 1.5668, -0.3024,  2.9477,  ..., -0.0947, -1.1791,  0.7230],\n",
      "          [ 1.2397,  0.5383, -0.0487,  ...,  0.0349, -0.9806,  0.3859],\n",
      "          ...,\n",
      "          [ 0.0846,  0.7211,  1.0244,  ...,  2.1696,  0.4172,  0.4975],\n",
      "          [ 0.7079,  1.0968,  1.8644,  ..., -0.6827,  2.5922,  0.5941],\n",
      "          [-0.0884, -0.3710,  1.3271,  ..., -2.8441, -1.8396,  0.9546]],\n",
      "\n",
      "         [[ 0.6916, -2.9077,  0.1205,  ..., -0.1828, -0.9193, -0.2593],\n",
      "          [-0.1728, -0.5608, -0.4392,  ..., -1.1855, -1.4503,  0.1957],\n",
      "          [ 0.3062,  0.5049, -0.3120,  ...,  1.5578, -0.8610,  0.9107],\n",
      "          ...,\n",
      "          [ 1.4097, -1.5041, -0.9994,  ..., -1.2066,  0.7227, -0.2643],\n",
      "          [-0.3610, -1.3535, -1.6185,  ..., -0.1890,  1.1294,  0.4125],\n",
      "          [ 1.5944, -0.5158, -0.5288,  ...,  0.2175,  2.0340, -2.2105]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.1538,  0.7450, -1.7437,  ...,  0.8876,  0.0416,  0.5494],\n",
      "          [-2.6871, -0.7483, -0.1446,  ..., -0.6771, -1.0101,  1.1926],\n",
      "          [-0.1967, -0.4958, -0.1165,  ...,  1.5940,  2.2018, -0.9819],\n",
      "          ...,\n",
      "          [ 0.0076,  1.0532, -1.3597,  ...,  0.7880, -2.8886,  0.7693],\n",
      "          [ 0.0209,  1.5573, -1.5320,  ...,  1.6739, -1.0163, -1.0847],\n",
      "          [ 1.5603, -2.2389,  2.7317,  ..., -2.5090, -0.5478, -0.2579]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Dropout2d(p=0.2)\n",
    "input = torch.randn(20, 16, 32, 32)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Dropout3d(p=0.5, inplace=False)\n",
    "与前面的类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.AlphaDropout(p=0.5)\n",
    "在输入上应用 Alpha Dropout。Alpha Dropout 在训练期间, 按照伯努利概率分布, 以概率 p 随机地将输入张量中的部分元素 置进行掩盖, 在每次调用中, 被掩盖的元素是随机的, 并且对输出会进行缩放、变换等操作 以保持均值为 0、标准差为 1。更多信息请参考论文: [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"SparseLayer\"></div>Sparse layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False, _weight=None)\n",
    "一个保存了固定字典和大小的简单查找表。这个模块常用来保存词嵌入（word embeddings）和用下标检索它们。模块的输入是一个下标的列表，输出是对应的词嵌入。\n",
    "\n",
    "**参数**\n",
    "- num_embeddings (int) - 嵌入字典的大小\n",
    "- embedding_dim (int) - 每个嵌入向量的大小\n",
    "- padding_idx (int, optional) - 如果提供的话，输出遇到此下标时用零填充\n",
    "- max_norm (float, optional) - 如果提供的话，会重新归一化词嵌入，使它们的范数小于提供的值\n",
    "- norm_type (float, optional) - 对于max_norm选项计算p范数时的p\n",
    "- scale_grad_by_freq (boolean, optional) - 如果提供的话，会根据字典中单词频率缩放梯度\n",
    "\n",
    "**变量**\n",
    "- weight (Tensor) -形状为(num_embeddings, embedding_dim)的模块中可学习的权值\n",
    "\n",
    "**形状**\n",
    "- 输入： 任意形状的LongTensor，包含了要提取的索引。\n",
    "- 输出： (*，embedding_dim)，*指的是输入的形状\n",
    "\n",
    "注意：只有有限数量的优化器支持稀疏梯度。目前有 `optim.SGD`(CUDA和CPU)，`optim.SparseAdam`(CUDA和CPU)，以及`optim.Adagrad`(CPU)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7935, -1.4070, -0.4081],\n",
      "         [ 0.6319,  0.4839, -0.6100],\n",
      "         [-0.6429, -0.9572,  0.7497],\n",
      "         [-0.7222,  1.0039,  0.8132]],\n",
      "\n",
      "        [[-0.6429, -0.9572,  0.7497],\n",
      "         [-0.7251, -1.9815,  1.0354],\n",
      "         [ 0.6319,  0.4839, -0.6100],\n",
      "         [ 0.0495,  0.5817,  2.4680]]])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [-0.7291,  0.9612,  0.3609],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.8209, -0.2717,  1.3294]]])\n"
     ]
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "print(embedding(input))\n",
    "\n",
    "# example with padding_idx\n",
    "embedding = nn.Embedding(10, 3, padding_idx=0)\n",
    "input = torch.LongTensor([[0,2,0,5]])\n",
    "print(embedding(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classmethod from_pretrained(embeddings, freeze=True)\n",
    "从给定的2维的FloatTensor创建嵌入实例。\n",
    "\n",
    "**参数**\n",
    "- embeddings(Tensor)：包含Embedding权重的FloatTensor。第一维是被传递到Embedding的`num_embeddings`；第二维是`embedding_dim`\n",
    "- freeze(boolean,optional)：如果为真，则tensor在学习过程中不更新。相当于：embedding.weight.requires_grad = False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.0000,  5.1000,  6.3000]])\n"
     ]
    }
   ],
   "source": [
    "# FloatTensor containing pretrained weights\n",
    "weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "# Get embeddings for index 1\n",
    "input = torch.LongTensor([1])\n",
    "print(embedding(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False)\n",
    "计算一 个’bags’ 里的 embeddings的均值或和, 不用实例化中间的embeddings。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"DistanseFunction\"></div>Distance functions\n",
    "### class torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "返回沿着 dim 方向计算的 x1 与 x2 之间的余弦相似度。\n",
    "\n",
    "**Parameters**\n",
    "- dim (int, optional) – 计算余弦相似度的维度. Default: 1\n",
    "- eps (float, optional) – 小的值以避免被零除. Default: 1e-8\n",
    "\n",
    "**Shape**\n",
    "- Input1: (∗1,D,∗2), 其中的 D 表示 dim 的位置\n",
    "- Input2: (∗1,D,∗2), 与 Input1 一样的 shape\n",
    "- Output: (∗1,∗2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.PairwiseDistance(p=2, eps=1e-06, keepdim=False)\n",
    "计算`batchwise pairwise distance`，向量v1和v2通过计算p范数得到。\n",
    "\n",
    "**Shape**\n",
    "- Input1: (N,D), 其中的 D = vector dimension(向量维度)\n",
    "- Input2: (N,D), 与 Input1 的 shape 一样\n",
    "- Output: (N)，若keepdim=False，就是(N,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist = nn.PairwiseDistance(p=2)\n",
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "output = pdist(input1, input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"LossFunctions\"></div>Loss functions\n",
    "### class torch.nn.L1Loss(size_average=True, reduce=True)\n",
    "L1损失。逐元素地求出输入x和目标y之间差的绝对值，最后返回绝对值的平均值。即绝对值损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.MSELoss(size_average=True, reduce=True)\n",
    "输入 x 和 目标 y 之间的均方误差。也就是平方损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)\n",
    "交叉熵损失函数。\n",
    "### class torch.nn.NLLLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)\n",
    "负对数似然损失（negative log likelihood loss）。\n",
    "\n",
    "损失函数还有很多，后续用到再做补充。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"VisionLayer\"></div> Vision layers\n",
    "\n",
    "### class torch.nn.PixelShuffle(upscale_factor)\n",
    "将shape为$[*, r^2C, H, W]$的Tensor重新排列为shape为$[C, rH, rW]$的Tensor。当使用 stride = 1/r 的高效子像素卷积很有用。参见[Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network](https://arxiv.org/abs/1609.05158)。\n",
    "\n",
    "**参数**\n",
    "- upscale_factor (int) – 增加空间分辨率的因子\n",
    "\n",
    "**Shape**\n",
    "- 输入: (N,C∗upscale_factor^2,H,W)\n",
    "- 输出: (N,C,H∗upscale_factor,W∗upscale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None)\n",
    "对给定的多通道一维时序数据, 二维空间数据, 或三维容积数据进行上采样。\n",
    "\n",
    "输入数据的格式为 minibatch x channels x depth x height x width. 因此, 对于2-D数据的输入, 期望得到一个4-D张量；对于3-D数据输入, 期望得到一个5-D张量。对3D, 4D, 5D的输入张量进行最近邻、线性、双线性和三线性采样, 可用于该上采样方法。\n",
    "\n",
    "可以提供 scale_factor 或目标输出的 size 来计算输出的大小。（不能同时都给, 因为这样做是含糊不清的）\n",
    "\n",
    "**参数**\n",
    "- size (tuple, optional) – 整型数的元组 ([D_out], [H_out], W_out) 的输出大小\n",
    "- scale_factor (int / tuple of python:ints, optional) – 图像高度/宽度/深度的乘子\n",
    "- mode (string, optional) – 上采样算法: nearest | linear | bilinear | trilinear. 默认为: nearest\n",
    "\n",
    "**Shape**\n",
    "- 输入: (N,C,Win), (N,C,Hin,Win) 或 (N,C,Din,Hin,Win)\n",
    "- 输出: (N,C,Wout), (N,C,Hout,Wout) 或 (N,C,Dout,Hout,Wout) 其中: Dout=floor(Din∗scale_factor) 或 size[-3] Hout=floor(Hin∗scale_factor) 或 size[-2] Wout=floor(Win∗scale_factor) 或 size[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]]]])\n",
      "tensor([[[[ 1.,  1.,  2.,  2.],\n",
      "          [ 1.,  1.,  2.,  2.],\n",
      "          [ 3.,  3.,  4.,  4.],\n",
      "          [ 3.,  3.,  4.,  4.]]]])\n",
      "tensor([[[[ 1.0000,  1.2500,  1.7500,  2.0000],\n",
      "          [ 1.5000,  1.7500,  2.2500,  2.5000],\n",
      "          [ 2.5000,  2.7500,  3.2500,  3.5000],\n",
      "          [ 3.0000,  3.2500,  3.7500,  4.0000]]]])\n",
      "tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],\n",
      "          [ 1.6667,  2.0000,  2.3333,  2.6667],\n",
      "          [ 2.3333,  2.6667,  3.0000,  3.3333],\n",
      "          [ 3.0000,  3.3333,  3.6667,  4.0000]]]])\n",
      "tensor([[[[ 1.,  2.,  0.],\n",
      "          [ 3.,  4.,  0.],\n",
      "          [ 0.,  0.,  0.]]]])\n",
      "tensor([[[[ 1.0000,  1.2500,  1.7500,  1.5000,  0.5000,  0.0000],\n",
      "          [ 1.5000,  1.7500,  2.2500,  1.8750,  0.6250,  0.0000],\n",
      "          [ 2.5000,  2.7500,  3.2500,  2.6250,  0.8750,  0.0000],\n",
      "          [ 2.2500,  2.4375,  2.8125,  2.2500,  0.7500,  0.0000],\n",
      "          [ 0.7500,  0.8125,  0.9375,  0.7500,  0.2500,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])\n",
      "tensor([[[[ 1.0000,  1.4000,  1.8000,  1.6000,  0.8000,  0.0000],\n",
      "          [ 1.8000,  2.2000,  2.6000,  2.2400,  1.1200,  0.0000],\n",
      "          [ 2.6000,  3.0000,  3.4000,  2.8800,  1.4400,  0.0000],\n",
      "          [ 2.4000,  2.7200,  3.0400,  2.5600,  1.2800,  0.0000],\n",
      "          [ 1.2000,  1.3600,  1.5200,  1.2800,  0.6400,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tina/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(1, 5).view(1, 1, 2, 2)\n",
    "print(input)\n",
    "m = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "print(m(input))\n",
    "\n",
    "m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False\n",
    "print(m(input))\n",
    "\n",
    "m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "print(m(input))\n",
    "\n",
    "# Try scaling the same data in a larger tensor\n",
    "input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3)\n",
    "input_3x3[:, :, :2, :2].copy_(input)\n",
    "print(input_3x3)\n",
    "\n",
    "m = nn.Upsample(scale_factor=2, mode='bilinear')  # align_corners=False\n",
    "# Notice that values in top left corner are the same with the small input (except at boundary)\n",
    "print(m(input_3x3))\n",
    "\n",
    "m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "# Notice that values in top left corner are now changed\n",
    "print(m(input_3x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.UpsamplingNearest2d(size=None, scale_factor=None)\n",
    "对多个输入通道组成的输入信号进行2维最近邻上采样。为了指定尺度, 提供了 size 或 scale_factor 作为构造参数。当给定 size, 输出图像的大小为 (h, w)。\n",
    "\n",
    "**Parameters**\n",
    "- size (tuple, optional) – 输出图片大小的整型元组(H_out, W_out)\n",
    "- scale_factor (int, optional) – 图像的 长和宽的乘子。\n",
    "\n",
    "**Shape**\n",
    "- Input: (N,C,Hin,Win)\n",
    "- Output: (N,C,Hout,Wout) 其中 Hout=floor(Hin∗scale_factor) ，Wout=floor(Win∗scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]]]])\n",
      "tensor([[[[ 1.,  1.,  2.,  2.],\n",
      "          [ 1.,  1.,  2.,  2.],\n",
      "          [ 3.,  3.,  4.,  4.],\n",
      "          [ 3.,  3.,  4.,  4.]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tina/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:173: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.Upsample instead.\n",
      "  warnings.warn(\"nn.UpsamplingNearest2d is deprecated. Use nn.Upsample instead.\")\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(1, 5).view(1, 1, 2, 2)\n",
    "print(input)\n",
    "m = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.UpsamplingBilinear2d(size=None, scale_factor=None)\n",
    "对多个输入通道组成的输入信号进行2维双线性上采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]]]])\n",
      "tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],\n",
      "          [ 1.6667,  2.0000,  2.3333,  2.6667],\n",
      "          [ 2.3333,  2.6667,  3.0000,  3.3333],\n",
      "          [ 3.0000,  3.3333,  3.6667,  4.0000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tina/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:221: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\")\n"
     ]
    }
   ],
   "source": [
    "input = torch.arange(1, 5).view(1, 1, 2, 2)\n",
    "print(input)\n",
    "m = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "print(m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"Multi-GPU\"></div>DataParallel layers (multi-GPU, distributed)\n",
    "\n",
    "### class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)\n",
    "在模块级别实现数据并行性。此容器通过将mini-batch划分到不同的设备上来实现给定module的并行。在forward过程中，module会在每个设备上都复制一遍，每个副本都会处理部分输入。在backward过程中，副本上的梯度会累加到原始module上。\n",
    "\n",
    "batch的大小应该大于所使用的GPU的数量。还应当是GPU个数的整数倍，这样划分出来的每一块都会有相同的样本数量。参见:[Use nn.DataParallel instead of multiprocessing](../介绍/3.Cuda语义.ipynb)\n",
    "\n",
    "除了Tensor，任何位置参数和关键字参数都可以传到DataParallel中。所有的变量会通过指定的dim来划分（默认值为0）。原始类型将会被广播，但是所有的其它类型都会被浅拷贝。所以如果在模型的forward过程中写入的话，将会被损坏。\n",
    "\n",
    "**参数说明**\n",
    "- module – 要被并行的module\n",
    "- device_ids – CUDA设备，默认为所有设备。\n",
    "- output_device – 输出设备（默认为device_ids[0]）\n",
    "```python\n",
    "net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n",
    "output = net(input_var)\n",
    "```\n",
    "\n",
    "### class torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0, broadcast_buffers=True)\n",
    "在模块级别实现分布式数据并行。此容器通过将mini-batch划分到不同的设备上来实现给定module的并行。module会在每个设备上都复制一遍，每个副本都会处理部分输入。在backward过程中，来自每个节点的梯度被平均。参见:[Use nn.DataParallel instead of multiprocessing](../介绍/3.Cuda语义.ipynb)\n",
    "\n",
    "这个类的创建要求在进程组模式中已经初始化了分布式包。参见[torch.distributed.init_process_group()](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group)\n",
    "\n",
    "```python\n",
    "torch.distributed.init_process_group(world_size=4, init_method='...')\n",
    "net = torch.nn.DistributedDataParallel(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div id = \"Utilities\"></div>Utilities(工具包)\n",
    "### torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2)\n",
    "这个函数是根据参数的范数来衡量的。用于梯度裁剪。范数是对所有梯度进行计算的，等价于把所有输入变量的梯度连接成一个向量，然后对这个向量按范数进行裁剪。梯度将会被原地修改。\n",
    "\n",
    "**参数**\t\n",
    "- parameters (Iterable[Variable]) – 一个可迭代Tensor, 梯度会被正规化\n",
    "- max_norm (float or int) – 梯度的最大范数\n",
    "- norm_type (float or int) – p 范数(指定 p ). 用 'inf' 表示无穷范数\n",
    "\n",
    "### torch.nn.utils.clip_grad_value_(parameters, clip_value)\n",
    "以一个特定值裁切一个可迭代参数的梯度。梯度将会被原地修改。\n",
    "### torch.nn.utils.weight_norm(module, name='weight', dim=0)\n",
    "将权重标准化应用于给定模块中的指定参数。权重标准化是一个重新参数化的过程，它将权重张量的大小从它的方向中分离出来。该函数会用两个参数通过名字 (e.g.“weight”)代替所指定的参数：一个指定参数的大小 (e.g. “weight_g”), 一个指定参数的方向“weight_v”（）。权重归一化是通过一个hook实现的, 该hook会在forward的每次调用之前根据大小和方向(两个新参数)重新计算权重张量。\n",
    "\n",
    "默认情况下, dim=0, 范数会在每一个输出的 channel/plane 上分别计算。 若要对整个权重张量计算范数, 使用 dim=None。\n",
    "\n",
    "参见：https://arxiv.org/abs/1602.07868\n",
    "\n",
    "\n",
    "**参数**\t\n",
    "- module (nn.Module) – 给定的 module\n",
    "- name (str, optional) – 权重参数的 name\n",
    "- dim (int, optional) – 进行范数计算的维度\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = weight_norm(nn.Linear(20, 40), name='weight')\n",
    "print(m.weight_g.size())\n",
    "print(m.weight_v.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.utils.remove_weight_norm(module, name='weight')\n",
    "从模块中移除权重归一化再参数化。\n",
    "```python\n",
    "m = weight_norm(nn.Linear(20, 40))\n",
    "remove_weight_norm(m)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PackedSequence\n",
    "关于RNN部分，待补充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
